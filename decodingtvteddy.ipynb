{
	"nbformat": 4,
	"nbformat_minor": 0,
	"metadata": {
		"orig_nbformat": 4,
		"language_info": {
			"name": "python",
			"version": "3.9.6",
			"mimetype": "text/x-python",
			"codemirror_mode": {
				"name": "ipython",
				"version": 3
			},
			"pygments_lexer": "ipython3",
			"nbconvert_exporter": "python",
			"file_extension": ".py"
		},
		"kernelspec": {
			"name": "python3",
			"display_name": "Python 3.9.6 64-bit (windows store)"
		},
		"interpreter": {
			"hash": "5f446e82410df0848bb4230c1816c047ca45b3a295b127db82d557e37c765b57"
		},
		"colab": {
			"name": "decodingtvteddy.ipynb",
			"provenance": [],
			"collapsed_sections": []
		}
	},
	"cells": [{
		"cell_type": "markdown",
		"metadata": {
			"id": "7anylyEd5S0w"
		},
		"source": ["This script decodes the TV Teddy video-embedded audio track in a video file sourced from official TV Teddy VHS recordings.\n", "\n", "\n", "\n", "First we get all our imports performed here. If there any problems we'll know\n", "before we get started. If running on a cloud Jupyter service such as Google Colab or Jetbrains Datalore then you have 'all batteries included'.\n", "\n", "On a local machine you will likely need to run:\n", "1. pip install opencv-python\n", "2. pip install librosa\n", "3. pip install matplotlib\n", "\n", "If running on Windows 10, you may need to enable LongPaths if installing librosa causes errors. In PowerShell:\n", "New-ItemProperty -Path \"HKLM:\\SYSTEM\\CurrentControlSet\\Control\\FileSystem\" -Name \"LongPathsEnabled\" -Value 1 -PropertyType DWORD -Force\n", "\n", "If running on a local machine you will also need to comment out the drive.mount() command in the first code block."]
	}, {
		"cell_type": "code",
		"metadata": {
			"id": "ufL0eprS5S0y"
		},
		"source": ["import cv2\n", "import array\n", "import wave\n", "import librosa\n", "import IPython.display as idp\n", "from google.colab import drive\n", "drive.mount('/content/gdrive')\n", "\n", "%matplotlib inline\n", "import matplotlib.pyplot as plt\n", "import librosa.display\n", "\n", "media_file_path = '/content/gdrive/MyDrive/Colab Notebooks/decodingtvteddy_media/'"],
		"execution_count": null,
		"outputs": []
	}, {
		"cell_type": "markdown",
		"metadata": {
			"id": "3d1I4Iap5S0y"
		},
		"source": ["Let's get started then - read the video file and extract every 100th frame"]
	}, {
		"cell_type": "code",
		"metadata": {
			"id": "VpFjVuWJ5S0y"
		},
		"source": ["vidcap = cv2.VideoCapture(media_file_path + 'TVTeddy 640x480 29.97fps 2Mbps.mp4')\n", "success, image = vidcap.read()\n", "count = 0\n", "success = True\n", "while success:\n", "    success,image = vidcap.read()\n", "    count += 1\n", "    if count % 100 == 0:\n", "        print('count of frames so far =', count)\n", "        cv2.imwrite(media_file_path + \"frame%d.jpg\" % count, image)  # save frame as JPEG file\n", "\n", "print('total count of frames =', count)"],
		"execution_count": null,
		"outputs": []
	}, {
		"cell_type": "markdown",
		"metadata": {
			"id": "OIYtu3yL5S0z"
		},
		"source": ["In the media folder, four frame images have been extracted. This shows that:\n", "1. The video file is OK and we will certainmly be able to get to each frame.\n", "2. The video-emebedded audio is clearly visible!\n", "Here is frame 300:"]
	}, {
		"cell_type": "code",
		"metadata": {
			"id": "Nvc6pwZy5S00"
		},
		"source": ["idp.Image(media_file_path + \"frame300.jpg\")"],
		"execution_count": null,
		"outputs": []
	}, {
		"cell_type": "markdown",
		"metadata": {
			"id": "aXG2g6gf5S00"
		},
		"source": ["Inspecting this image, the video-embedded-audio extens horizontally fropm pixel 1 to pixel 8 in this 640 x 480 image.\n", "Vertically, that 'audio' extends from pixel 4 to 432.\n", "\n", "So my plan is to:\n", "\n", "1. Read each frame, and do this:\n", "\n", "    1a. Set a loop running from value 0 to value 639 and, at each position (5, 2) through to (5, 432) do these steps:\n", "\n", "\t    1aa. Read the RGB value of the pixels and add those three values together together, subtracting 127 from each so that the waveform centres on value 0 and not on value 127. The values will be sampled between 0 and 255 so subtracting 127 will make them become sampled between 128 and -127. ‘Silence’ (denoted by grey rather than black or white) will then be recorded at 0 and not at 127. Summing the three R, G, and B samples will help with any subtlety that can still be derived from the change in greyness from sample to sample despite digitisation. I’ll save this value as a 16-bit signed integer.\n", "\n", "\t    1ab. Append the value to the end of an array which later is saved to the WAV file.\n", "\n", "2. 'Normalise' the array of audio samples; that is, ‘amplify’ the sample values and re-centre them around the ‘0’ centre line.\n", "\n", "3. Save the array of samples in a WAV file requested to playback at 30 fps x (432 - 2) frame-lines per second = 12900 KHz sample rate with 16bit sample size."]
	}, {
		"cell_type": "markdown",
		"metadata": {
			"id": "d9Afkw0al8uZ"
		},
		"source": ["First set up the necessary variables, including the audio line modulation start end end lines, then open the file:"]
	}, {
		"cell_type": "code",
		"metadata": {
			"id": "fMRgTXwp5S00"
		},
		"source": ["# A flag used to find out if the next video frame was read successfully\n", "success = True\n", "\n", "# Audio samples are counted into this variable:\n", "currentSampleCount = 0\n", "\n", "# This is the output WAV file's sample rate that will be written into its header information\n", "wavSampleRate = 20483\n", "# Each WAV file sample is 2 bytes (16-bit)\n", "wavSampleSize = 2\n", "\n", "# The Wav file will have a single mono audio channel\n", "wavChannels = 1\n", "\n", "# An array that will store all samples in a 16-bit signed integer format\n", "sampleArray = array.array('h')\n", "\n", "# The top and bottom video lines in the video frame where will measure the greyscale to get samples\n", "# increase audioLineModulationStartLine and decrease audioLineModulationEndLine until the loud 60Hz buzz disappears\n", "# from the finished audio\n", "audioLineModulationStartLine = 2\n", "audioLineModulationEndLine = 432\n", "\n", "# The horizontal position in the video frame where we will take the sample - ideally set to be in the centre\n", "# of the greyscale audio line\n", "audioLineCentrePixelToRead = 5\n", "\n", "frameCount = 0\n", "\n", "# Open the video file\n", "vidcap = cv2.VideoCapture(media_file_path + 'TVTeddy 640x480 29.97fps 2Mbps.mp4')\n"],
		"execution_count": null,
		"outputs": []
	}, {
		"cell_type": "markdown",
		"metadata": {
			"id": "OD4uydW8kk1g"
		},
		"source": ["Process the file, frame by frame"]
	}, {
		"cell_type": "code",
		"metadata": {
			"id": "1ldKPIPTkpj5"
		},
		"source": ["if vidcap.isOpened():\n", "    # Get some info on the file\n", "    width = vidcap.get(cv2.CAP_PROP_FRAME_WIDTH)  # float\n", "    height = vidcap.get(cv2.CAP_PROP_FRAME_HEIGHT)  # float\n", "    fps = vidcap.get(cv2.CAP_PROP_FPS)\n", "    frameCount = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n", "    print('Incoming Video: Width=', width, ', height=', height, ', fps=', fps, ', framecount=', frameCount)\n", "\n", "    # Process the file frame by frame\n", "    for currentFrame in range(0, frameCount):\n", "        success, image = vidcap.read()\n", "\n", "        if success:\n", "            # For the current frame, read the grey line and extract a sample from each pixel\n", "            for scanLine in range(audioLineModulationStartLine, audioLineModulationEndLine + 1):\n", "                sampleValue = 0\n", "                for rgb in range(0, 3):\n", "                    sampleValue += int(image[scanLine, audioLineCentrePixelToRead, rgb])\n", "                sampleArray.append(sampleValue)\n", "\n", "        else:\n", "            print('Failed to read frame', currentFrame)\n", "\n", "        if currentFrame % 100 == 0:\n", "            print('count of frames so far =', currentFrame, ' - ', int(currentFrame * 100 / frameCount), \"%\")\n", "\n", "    # Close the incoming video file\n", "    vidcap.release()\n", "\n", "print('Total count of frames =', frameCount)\n", "print('Total count of samples =', currentSampleCount)"],
		"execution_count": null,
		"outputs": []
	}, {
		"cell_type": "markdown",
		"metadata": {
			"id": "CCWsJGMDk5Rj"
		},
		"source": ["Analyse the extracted audio to obtain the max and average sample value"]
	}, {
		"cell_type": "code",
		"metadata": {
			"id": "CmhFOk3clDUK"
		},
		"source": ["print('Analysing extracted audio...')\n", "# Find the sum of sample sizes and the minimum & maximum sample size\n", "sumSampleSize = 0\n", "maxSampleValue = 0\n", "\n", "for sampleIndex in range(0, len(sampleArray) - 1):\n", "    sumSampleSize += sampleArray[sampleIndex]\n", "    if maxSampleValue < sampleArray[sampleIndex]:\n", "        maxSampleValue = sampleArray[sampleIndex]\n", "\n", "# Calculate mean average sample size\n", "meanSampleSize = int(sumSampleSize / len(sampleArray))\n", "\n", "print(\"max sample value\", maxSampleValue)\n", "print(\"mean average sample value\", meanSampleSize)\n"],
		"execution_count": null,
		"outputs": []
	}, {
		"cell_type": "markdown",
		"metadata": {
			"id": "YumF2O6tkOBf"
		},
		"source": ["Now alter the sample values to become rebalanced around zero based\n", "on the mean sample size, and amplified by multiplying the samples\n", "based on the amplifyValue - a process called 'normalisation':"]
	}, {
		"cell_type": "code",
		"metadata": {
			"id": "TwmnhJ2FkJI8"
		},
		"source": ["print('Normalising....')\n", "maxSampleValue = maxSampleValue - meanSampleSize\n", "amplifyValue = 16000 / maxSampleValue  # reduce constant value 16000 if Warnings below keep happening\n", "for sampleIndex in range(0, len(sampleArray)):\n", "    # Safety catch shown multiplication make signed integer too big or too small for the array\n", "    try:\n", "        sampleArray[sampleIndex] = int((sampleArray[sampleIndex] - meanSampleSize) * amplifyValue)\n", "    except OverflowError:\n", "        # sampleArray[sampleIndex] is kept at the same value\n", "        print(\"Warning: Normalised sample was too large or too small for signed 16-bit array\")\n", "        continue\n", "\n", "print('Normalisation completed')"],
		"execution_count": null,
		"outputs": []
	}, {
		"cell_type": "markdown",
		"metadata": {
			"id": "Qgp9Jc6LkzSN"
		},
		"source": ["Write the samples to a WAV file"]
	}, {
		"cell_type": "code",
		"metadata": {
			"id": "ucCBfAQIk1pe"
		},
		"source": ["print('Writing WAV file...')\n", "f = wave.open(media_file_path + 'output.wav', 'w')\n", "f.setparams((wavChannels, wavSampleSize, wavSampleRate, len(sampleArray), \"NONE\", \"Uncompressed\"))\n", "f.writeframes(sampleArray.tobytes())  # Important to convert to string or only half the audio will be written out\n", "f.close()\n", "\n", "print('Completed!')"],
		"execution_count": null,
		"outputs": []
	}, {
		"cell_type": "markdown",
		"metadata": {
			"id": "MhRBaOLr5S02"
		},
		"source": ["Let's take a look at the output:"]
	}, {
		"cell_type": "code",
		"metadata": {
			"id": "6hKYS_0l5S02"
		},
		"source": ["x, sr = librosa.load(media_file_path + 'output.wav')\n", "print(\"The number of samples is\", x.shape, \"and the sample rate is\", sr)\n", "\n", "plt.figure(figsize=(14, 5))\n", "librosa.display.waveplot(x, sr=sr)\n", "\n"],
		"execution_count": null,
		"outputs": []
	}, {
		"cell_type": "markdown",
		"metadata": {
			"id": "5IKQvH0v5S02"
		},
		"source": ["Let's have a listen:"]
	}, {
		"cell_type": "code",
		"metadata": {
			"id": "wvjy38Cg5S03"
		},
		"source": ["idp.Audio(media_file_path + \"output.wav\")"],
		"execution_count": null,
		"outputs": []
	}]
}
